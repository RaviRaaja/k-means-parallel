{
 "metadata": {
  "name": "",
  "signature": "sha256:5205ccd0167eb86cdd7e3ac7a11047de204bc6417dd14c494596528382546fe4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from IPython import parallel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc = parallel.Client()\n",
      "# load balanced view\n",
      "d_view = rc[:]\n",
      "# do synchronized processing\n",
      "d_view.block=True\n",
      "\n",
      "# import Numpy\n",
      "with d_view.sync_imports():\n",
      "    import numpy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "importing numpy on engine(s)\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def initial_centroids(data, k):\n",
      "    ''' select k random data points from the data'''\n",
      "    return data[numpy.random.choice(range(data.shape[0]), k, replace=False)]\n",
      "\n",
      "def compare_centroids(old_centroids, new_centroids, precision=-1):\n",
      "    if precision == -1:\n",
      "        return np.array_equal(old_centroids, new_centroids)\n",
      "    else:\n",
      "        diff = np.sum((new_centroids - old_centroids)**2, axis=1)\n",
      "        if np.max(diff) <= precision:\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "\n",
      "def lloyds_iteration(data, centroids):\n",
      "    # find the Euclidean distance between a center and a data point\n",
      "    # centroids array shape = k x m\n",
      "    # data array shape = n x m\n",
      "    # In order to broadcast it, we have to introduce a third dimension into data\n",
      "    # data array becomes n x 1 x m\n",
      "    # now as a result of broadcasting, both array sizes will be n x k x m\n",
      "    data_ex = data[:, numpy.newaxis, :]\n",
      "    euclidean_dist = (data_ex - centroids) ** 2\n",
      "    # now take the summation of all distances along the 3rd axis(length of the dimension is m).\n",
      "    # This will be the total distance from each centroid for each data point.\n",
      "    # resulting vector will be of size n x k\n",
      "    distance_arr = numpy.sum(euclidean_dist, axis=2)\n",
      "\n",
      "    # now we need to find out to which cluster each data point belongs.\n",
      "    # Use a matrix of n x k where [i,j] = 1 if the ith data point belongs\n",
      "    # to cluster j.\n",
      "    min_location = numpy.zeros(distance_arr.shape)\n",
      "    min_location[range(distance_arr.shape[0]), numpy.argmin(distance_arr, axis=1)] = 1\n",
      "\n",
      "    # calculate J\n",
      "    j_val = numpy.sum(distance_arr[min_location == True])\n",
      "\n",
      "    # calculates the new centroids\n",
      "    new_centroids = numpy.empty(centroids.shape)\n",
      "    membership_count = numpy.empty(centroids.shape[0])\n",
      "    for col in range(0, centroids.shape[0]):\n",
      "        new_centroids[col] = numpy.mean(data[min_location[:, col] == True, :], axis=0)\n",
      "        membership_count[col] = numpy.count_nonzero(min_location[:, col])\n",
      "        \n",
      "    return {'j-value':j_val, 'centroids':new_centroids, 'element-count':membership_count}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.random.randn(1000000,2)\n",
      "# distribute the data among the engines\n",
      "d_view.scatter('data', data)\n",
      "centroids = np.array(d_view.apply(initial_centroids, parallel.Reference('data'),2)).reshape(4,2)\n",
      "stabilized = False\n",
      "iterations = 0\n",
      "while not stabilized:\n",
      "    iterations += 1\n",
      "    ret_vals = d_view.apply(lloyds_iteration, parallel.Reference('data'), centroids)\n",
      "    member_count = np.sum(np.array([r['element-count'] for r in ret_vals]).reshape(len(ret_vals),-1),axis=0)\n",
      "    local_sum = np.array([r['centroids'] * r['element-count'].reshape(-1,1) for r in ret_vals])\n",
      "    new_centroids = np.sum(local_sum, axis=0)/member_count.reshape(-1,1)\n",
      "    if compare_centroids(centroids, new_centroids):\n",
      "        stabilized = True\n",
      "    else:\n",
      "        centroids = new_centroids\n",
      "\n",
      "print('Iterations:', iterations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iterations: 178\n"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}